

-- INSTALL HELM --
Step 1: Install Helm
Helm Install Guide:   https://helm.sh/docs/intro/install/

-- HELM REPO --
Step 2: Add Prometheus Helm Repository
# helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
# helm repo update

COMMAND BREAK DOWN
* helm repo add         ///    Adds the Prometheus community repository to Helm.
* helm repo update     ///     Updates the local Helm repository cache.

-- INSTALL PROMETHEUS --
Step 3: Install Prometheus with Helm
Save the values in a "values.yaml" file to customize the installation.

# values.yaml

server:
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: "nginx"  # Modify if you use a different ingress controller
    hosts:
      - prometheus.example.com  # Replace with your domain
    pathType: Prefix
    path: /

-- we configure Prometheus to be accessible via an Ingress with a custom domain. 
   Adjust the hosts value to your domain.

Run the Helm installation command:
# helm install prometheus -n prometheus -f values.yaml prometheus-community/prometheus

COMMAND BREAK DOWN
* "helm install"          ///   Installs" the Prometheus Helm chart.
* "prometheus"            ///   Is the release name for this installation.
* "-n prometheus"         ///   Specifies namespace where Prometheus will be installed. ENSURE THAT NAMESPACE EXIST.
* "-f values.yaml"        ///   Specifies the values file to customize the installation.
* "prometheus-community/prometheus"    ///   Is the Helm chart to install.

Step 4: Verify Installation
Check the installation status and ensure that Prometheus pods are running:

# kubectl get pods -n prometheus
You should see Prometheus pods running. If the status is "Running," the installation was successful.

Step 5: Access Prometheus WEB UI
Open your browser and navigate to http://prometheus.example.com/.
REMEMBER: We specified this domain earlier in our values.yaml file. 

CONGRATS!!!
We installed Prometheus in your Kubernetes cluster using Helm and customized the installation with specific configuration values. 
You can further configure and integrate Prometheus as needed for your monitoring requirements.


-- LET'S CONFIGURE PROMETHEUS SERVER W/ SCRAPE TARGETS --
STEP 1: Create/Edit the values-custom.yaml file and specify the scrape target(s) for Prometheus.

i,e.
# custom-values.yaml
server:
  additionalScrapeConfigs:
    - job_name: 'my-new-service'
      kubernetes_sd_configs:
        - role: endpoints
      namespaces:
          names: [default]  # Limit to specific namespaces
      relabel_configs:
        - source_labels: [__meta_kubernetes_pod_container_port_name]
          action: keep
          regex: "http"



* 'kubernetes_sd_configs'    ///  specifies that Prometheus should use Kubernetes service discovery.
* 'role: endpoints'          ///  tells Prometheus to discover endpoints (pods).
* 'namespaces'               ///  allows you to limit the discovery to specific namespaces.
* 'relabel_configs'          ///  filter the discovered endpoints based on their labels. In this example, it selects pods with the app label set to my-app.
* 'action: keep'            ///   Specifies that you want to keep the scrape target if the conditions are met. 
                                  Other actions can include drop (discard the target) or replace (modify the target).
* 'regex: "http"            ///   "http": This is a regular expression that checks the value of the __meta_kubernetes_pod_container_port_name label.
                                  It will keep the target only if the value matches "http." 


- So how does the Prometheus server know where to find the pods?
<> Kubernetes Service Discovery: When Prometheus starts, it queries the Kubernetes API server for 
                                 the list of pods that match the criteria specified in the service discovery configuration. 
                                 This criteria often includes Kubernetes labels and annotations.

<> Dynamic Target Discovery: Prometheus dynamically discovers the pods that match the criteria and adds them as scrape targets. 
                             This process is automated and does not require manual intervention to update scrape targets.

<> Scraping: Prometheus regularly scrapes metrics from the discovered pods according to the scrape interval defined in the configuration.




Step 2: Upgrade Prometheus
To apply changes, we use 'helm upgrade' command with the release name and the path to the Helm chart:

# helm upgrade prometheus -n prometheus -f custom-values.yaml prometheus-community/prometheus

COMMAND BREAK DOWN
* 'prometheus'                       ///         is the release name.
* '-n prometheus'                   ///          specifies the namespace.
* '-f custom-values.yaml'           ///          specifies custom values file that includes the updated scrape target configuration.
* 'prometheus-community/prometheus' ///          is the Helm chart.

This command will upgrade the Prometheus deployment with the new configuration, including the updated scrape targets.

Step 3: Verify Changes
Verify changes by checking Prometheus pods to ensure they're running/collecting 
data from the updated scrape targets:

# kubectl get pods -n prometheus
Your Prometheus pods should show that they are running and ready. 
The changes to the scrape targets will take effect after the upgrade.


-- Let's Arm the Application --


STEP 1: Update pom.xml: Add Prometheus Java client library as a dependency. 
        Here's an example of how to do it:

<dependencies>
    <!-- Other dependencies -->
    <dependency>
        <groupId>io.prometheus</groupId>
        <artifactId>simpleclient</artifactId>
        <version>0.12.0</version>
    </dependency>
    <dependency>
        <groupId>io.prometheus</groupId>
        <artifactId>simpleclient_hotspot</artifactId>
        <version>0.12.0</version>
    </dependency>
    <!-- Additional Prometheus client libraries as needed -->
</dependencies>

This i.e, includes two common Prometheus client libraries for Java:
      - simpleclient 
      - Simpleclient_hotspot
        NOTE: You may need other libraries depending on your specific use case.


STEP 2: Instrument Code: 
You kneed to instrument your Java code to expose metrics using the following libraries. 

import io.prometheus.client.Counter;                <-------
import io.prometheus.client.exporter.HTTPServer;     <-------

public class Main {
    public static void main(String[] args) throws Exception {
        HTTPServer server = new HTTPServer(8080);

        Counter requests = Counter.build()
            .name("my_app_requests_total")
            .help("Total HTTP requests handled")
            .register();

        requests.inc();

        Thread.currentThread().join();
    }
}


-- WHAT THIS LOOKS LIKE FOR KUBERNETES DEPLOYMENT --

Remember: We've already exposed the metric in Step 1: 
Step 2: Create Kubernetes Deployment and Service.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: your-java-app-image:tag
          ports:
            - containerPort: 8080  # Expose the port your application is running on


---

NOTE: The 'Service' facilitates network communication to and from the POD. 

apiVersion: v1
kind: Service
metadata:
  name: my-app
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80  # Exposed port
      targetPort: 8080  # Match the container port



< DEPLOYMENT BREAK DOWN >

apiVersion: apps/v1: 
This line specifies the API version for the Kubernetes object being created. 
In this case, it's using the apps/v1 API version, which is commonly used for Deployments.

kind: Deployment: 
This line specifies that you are creating a Deployment object. 
A Deployment is a Kubernetes resource that defines a declarative way to manage applications.

metadata:: 
This section contains metadata about the Deployment, such as its name and labels.

name: my-app: 
This line specifies the name of the Deployment. In this example, it's named "my-app."

labels:: 
Labels are key-value pairs that can be attached to Kubernetes resources. 
Here, a label with the key "app" is set to the value "my-app." This label can be used for grouping and selecting resources.

spec:: 
The spec section defines the desired state of the Deployment.

replicas: 3: 
This line specifies that you want three replicas (copies) of your application pods 
to be running at all times. If a pod goes down, the Deployment will ensure that it's replaced.

template:: 
Inside the template section, you define the Pod template for the Deployment. 
This template is used to create individual pods that are part of the Deployment.

metadata:: 
Similar to the outer metadata section, this metadata section contains labels for the pods 
created from the template.

labels:: 
These labels are associated with the pods created from the template. 
In this case, the pods will also have the label "app: my-app."

spec:: 
Inside the template's spec section, you specify the configuration for the containers running in the pods.

containers:: 
This is a list of containers running in the pod. In this example, there's only one container named "my-app."

name: my-app: 
This line specifies the name of the container, which is set to "my-app."

image: 
your-java-app-image:tag: Here, you specify the Docker image for the container. 
Replace "your-java-app-image:tag" with the actual image name and tag for your Java application.

ports:: 
This section defines the ports that the container exposes.

- containerPort: 8080: It specifies that the container is listening on port 8080. 
This port is where your Java application inside the container is running and exposing its service.



< SERVICE BREAK DOWN >

apiVersion: v1: 
Specifies the API version for the Kubernetes Service.

kind: 
Service: Indicates that you are creating a Service resource in Kubernetes.

metadata:: 
This section contains metadata about the Service, such as its name.

name: my-app: 
Specifies the name of the Service, which is set to "my-app."

spec:: 
Defines the specifications for the Service.

selector:: 
This section defines a set of labels used to select the pods that the Service will route traffic to.

app: my-app: 
The selector specifies that the Service will route traffic to pods with the label "app: my-app," 
matching the labels of the pods created by the Deployment.

ports:: 
This section specifies the ports that the Service will listen on.

- protocol: TCP: Indicates that the Service is using the TCP protocol.

port: 80: 
Specifies the port on which the Service will listen. This is the port through which external 
clients can access the Service.

targetPort: 8080: 
Specifies the target port to which traffic will be routed within the pods. 
This matches the container port of the pods created by the Deployment. In this case, it routes 
traffic to port 8080 within the pods.


