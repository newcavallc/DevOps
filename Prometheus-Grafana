

** PROMETHEUS ARCHITECTURE EXPLAINED **

Targets (Applications and Services):
  * These are the applications, services, or devices you want to monitor.
  * Targets expose metrics and are the sources of monitoring data.

Prometheus Server:
  * The central component that collects, stores, and queries metrics.
  * Responsible for scraping (pulling) data from targets at specified intervals.

Exporters:
  * Optional components that help expose metrics from systems and services that don't natively support Prometheus.
  * Exporters act as bridges, converting other data formats into Prometheus-readable metrics.
  * Examples include Node Exporter, Blackbox Exporter, and more.

Service Discovery:
  * Part of the Prometheus server that dynamically discovers and monitors targets.
  * Supports various service discovery methods, including Kubernetes service discovery, DNS, file-based discovery, and more.
  * Data Storage (Time-Series Database, TSDB):

Prometheus stores collected metrics in its built-in time-series database.
  * Metrics are stored as time-series data, making it easy to query historical data.
  * The local storage can be configured to retain data for a defined retention period.

Alert Manager:
  * An independent component responsible for handling and managing alerts generated by Prometheus.
  * Provides features for deduplication, silencing, grouping, and routing alerts to appropriate recipients.

//////
The Alert Manager can alert you by:
Receiving Alerts: 
It receives alerts from the Prometheus server.

Processing and Grouping Alerts: 
The Alert Manager processes incoming alerts, groups related alerts, and deduplicates them.

Applying Notification Routing: 
It applies notification routing rules to determine which receivers (e.g., email, chat, webhook) should receive alerts.

Sending Notifications: It sends notifications to the configured receivers, such as 
email, chat, or other communication channels.

In summary, the Alert Manager acts as a central component for processing and routing alerts generated 
by Prometheus, ensuring that the right people or systems receive timely notifications about issues and incidents.
\\\\\\

Query Language and Web UI:
  * Users can interact with Prometheus through its query language (PromQL).
  * Prometheus provides a web-based user interface for querying and visualization.

Grafana (Optional):
  * An external visualization and dashboard tool that can be integrated with Prometheus.
  * Allows for creating custom dashboards and advanced visualization of Prometheus data.

Push Gateway (Optional):
  * An optional component that allows short-lived jobs to push their metrics to Prometheus.
  * Useful for batch jobs or jobs that can't be scraped by Prometheus.

-- INSTALL HELM --
Step 1: Install Helm
Helm Install Guide:   https://helm.sh/docs/intro/install/

-- HELM REPO --
Step 2: Add Prometheus Helm Repository
# helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
# helm repo update

COMMAND BREAK DOWN
* helm repo add         ///    Adds the Prometheus community repository to Helm.
* helm repo update     ///     Updates the local Helm repository cache.

-- INSTALL PROMETHEUS --
Step 3: Install Prometheus with Helm
Save the values in a "values.yaml" file to customize the installation.

# values.yaml

server:
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: "nginx"  # Modify if you use a different ingress controller
    hosts:
      - prometheus.example.com  # Replace with your domain
    pathType: Prefix
    path: /

-- we configure Prometheus to be accessible via an Ingress with a custom domain. 
   Adjust the hosts value to your domain.

Run the Helm installation command:
# helm install prometheus -n prometheus -f values.yaml prometheus-community/prometheus

COMMAND BREAK DOWN
* "helm install"          ///   Installs" the Prometheus Helm chart.
* "prometheus"            ///   Is the release name for this installation.
* "-n prometheus"         ///   Specifies namespace where Prometheus will be installed. ENSURE THAT NAMESPACE EXIST.
* "-f values.yaml"        ///   Specifies the values file to customize the installation.
* "prometheus-community/prometheus"    ///   Is the Helm chart to install.

Step 4: Verify Installation
Check the installation status and ensure that Prometheus pods are running:

# kubectl get pods -n prometheus
You should see Prometheus pods running. If the status is "Running," the installation was successful.

Step 5: Access Prometheus WEB UI
Open your browser and navigate to http://prometheus.example.com/.
REMEMBER: We specified this domain earlier in our values.yaml file. 

CONGRATS!!!
We installed Prometheus in your Kubernetes cluster using Helm and customized the installation with specific configuration values. 
You can further configure and integrate Prometheus as needed for your monitoring requirements.


-- LET'S CONFIGURE PROMETHEUS SERVER W/ SCRAPE TARGETS --
STEP 1: Create/Edit the values-custom.yaml file and specify the scrape target(s) for Prometheus.

i,e.
# custom-values.yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'my-app'
    kubernetes_sd_configs:
      - role: endpoints
    relabel_configs:
      - source_labels: [app]         
        action: keep                       
        regex: my-app                      
      - source_labels: [container_port] <---      We use yet another sourcel label for same job... Therefore we narrow down 
                                                  the selection of pods for scraping even further. 
        action: keep
        regex: "8080"

NOTICE ABOVE...
- source_labels: [app]                ///       Therefore if your Deployment App indicates the following:
                                                labels:
                                                  app: my-app  # Applying the "app" label to the pod template

                                                Prometheus will filter pods to monitor based on the "[app]" lable and "my-app" value.
                                                Prometheus will only scrape metrics from pods that match this label criteria.

< CONFIG BREAK DOWN >

GLOBAL SECTION:

global:: 
This section contains global settings for Prometheus.

scrape_interval: 15s: 
This line sets the global scrape interval, which is the frequency at which Prometheus scrapes metrics from its targets. 
In this case, it's set to every 15 seconds.

Scrape Configurations Section:

scrape_configs:: 
This section defines the scrape configurations, which specify the targets and settings for scraping metrics.

Job for Prometheus:

job_name: 'prometheus': 
This is a scrape configuration named 'prometheus.' It's used for scraping metrics from the Prometheus server itself.

static_configs:: 
Specifies static (fixed) scrape targets.

targets: ['localhost:9090']: 
This line specifies that Prometheus should scrape metrics from 'localhost' on port 9090, 
which is how Prometheus collects its own metrics.

Job for Your Application ('my-app'):

job_name: 'my-app': This is a scrape configuration named 'my-app,' representing your application's metrics.

kubernetes_sd_configs:: 
This section configures Kubernetes service discovery for finding scrape targets.

role: endpoints: 
Specifies the role for Kubernetes service discovery, focusing on endpoints (pods).

relabel_configs:: 
Defines relabeling configurations to filter or modify discovered targets.

source_labels: [app]: 
Source label for filtering.

action: keep: 
The action specifies to keep the target if conditions are met.

regex: my-app: 
Specifies the regex pattern. This line filters pods with the 'app' label set to 'my-app.'
Another relabeling rule filters pods with the 'container_port' label set to "8080."


PROMETHEUS SCRAPES ITSELF: 

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']


IT ALSO SCRAPE FOR:

Prometheus Uptime: 
Information about how long the Prometheus server has been running.

Resource Usage: 
Metrics related to CPU and memory usage by the Prometheus process.

Scrape and Alerting Information: 
Metrics related to the success and latency of scraping other targets 
(including your application) and alerting rule evaluations.

TSDB (Time-Series Database) Metrics: 
Data about the storage and management of time-series data, including information on 
disk space usage, retention policies, and more.

HTTP Request Statistics: 
Metrics related to HTTP requests to the Prometheus server, such as request counts, 
response times, and error rates.

Prometheus Configuration: 
Information about the configuration of Prometheus, including scrape targets and 
alerting rules.


- So how does the Prometheus server know where to find the pods?
<> Kubernetes Service Discovery: When Prometheus starts, it queries the Kubernetes API server for 
                                 the list of pods that match the criteria specified in the service discovery configuration. 
                                 This criteria often includes Kubernetes labels and annotations.

<> Dynamic Target Discovery: Prometheus dynamically discovers the pods that match the criteria and adds them as scrape targets. 
                             This process is automated and does not require manual intervention to update scrape targets.

<> Scraping: Prometheus regularly scrapes metrics from the discovered pods according to the scrape interval defined in the configuration.




Step 2: Upgrade Prometheus
To apply changes, we use 'helm upgrade' command with the release name and the path to the Helm chart:

# helm upgrade prometheus -n prometheus -f custom-values.yaml prometheus-community/prometheus

COMMAND BREAK DOWN
* 'prometheus'                       ///         is the release name.
* '-n prometheus'                   ///          specifies the namespace.
* '-f custom-values.yaml'           ///          specifies custom values file that includes the updated scrape target configuration.
* 'prometheus-community/prometheus' ///          is the Helm chart.

This command will upgrade the Prometheus deployment with the new configuration, including the updated scrape targets.

Step 3: Verify Changes
Verify changes by checking Prometheus pods to ensure they're running/collecting 
data from the updated scrape targets:

# kubectl get pods -n prometheus
Your Prometheus pods should show that they are running and ready. 
The changes to the scrape targets will take effect after the upgrade.


-- Let's Arm the Application --


STEP 1: Update pom.xml: Add Prometheus Java client library as a dependency. 
        Here's an example of how to do it:

<dependencies>
    <!-- Other dependencies -->
    <dependency>
        <groupId>io.prometheus</groupId>
        <artifactId>simpleclient</artifactId>
        <version>0.12.0</version>
    </dependency>
    <dependency>
        <groupId>io.prometheus</groupId>
        <artifactId>simpleclient_hotspot</artifactId>
        <version>0.12.0</version>
    </dependency>
    <!-- Additional Prometheus client libraries as needed -->
</dependencies>

This i.e, includes two common Prometheus client libraries for Java:
      - simpleclient 
      - Simpleclient_hotspot
        NOTE: You may need other libraries depending on your specific use case.


STEP 2: Instrument Code: 
You kneed to instrument your Java code to expose metrics using the following libraries. 

import io.prometheus.client.Counter;                <-------
import io.prometheus.client.exporter.HTTPServer;     <-------

public class Main {
    public static void main(String[] args) throws Exception {
        HTTPServer server = new HTTPServer(8080);

        Counter requests = Counter.build()
            .name("my_app_requests_total")
            .help("Total HTTP requests handled")
            .register();

        requests.inc();

        Thread.currentThread().join();
    }
}


-- WHAT THIS LOOKS LIKE FOR KUBERNETES DEPLOYMENT --

Remember: We've already exposed the metric in Step 1: 
Step 2: Create Kubernetes Deployment and Service.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
  labels:
    app: my-app          <---- Prometheus will filter based on the "app:" label
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app
          image: your-java-app-image:tag
          ports:
            - containerPort: 8080  # Expose the port your application is running on


---

NOTE: The 'Service' facilitates network communication to and from the POD. 

apiVersion: v1
kind: Service
metadata:
  name: my-app
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80  # Exposed port
      targetPort: 8080  # Match the container port



< DEPLOYMENT BREAK DOWN >

apiVersion: apps/v1: 
This line specifies the API version for the Kubernetes object being created. 
In this case, it's using the apps/v1 API version, which is commonly used for Deployments.

kind: Deployment: 
This line specifies that you are creating a Deployment object. 
A Deployment is a Kubernetes resource that defines a declarative way to manage applications.

metadata:: 
This section contains metadata about the Deployment, such as its name and labels.

name: my-app: 
This line specifies the name of the Deployment. In this example, it's named "my-app."

labels:: 
Labels are key-value pairs that can be attached to Kubernetes resources. 
Here, a label with the key "app" is set to the value "my-app." This label can be used for grouping and selecting resources.

spec:: 
The spec section defines the desired state of the Deployment.

replicas: 3: 
This line specifies that you want three replicas (copies) of your application pods 
to be running at all times. If a pod goes down, the Deployment will ensure that it's replaced.

template:: 
Inside the template section, you define the Pod template for the Deployment. 
This template is used to create individual pods that are part of the Deployment.

metadata:: 
Similar to the outer metadata section, this metadata section contains labels for the pods 
created from the template.

labels:: 
These labels are associated with the pods created from the template. 
In this case, the pods will also have the label "app: my-app."

spec:: 
Inside the template's spec section, you specify the configuration for the containers running in the pods.

containers:: 
This is a list of containers running in the pod. In this example, there's only one container named "my-app."

name: my-app: 
This line specifies the name of the container, which is set to "my-app."

image: 
your-java-app-image:tag: Here, you specify the Docker image for the container. 
Replace "your-java-app-image:tag" with the actual image name and tag for your Java application.

ports:: 
This section defines the ports that the container exposes.

- containerPort: 8080: It specifies that the container is listening on port 8080. 
This port is where your Java application inside the container is running and exposing its service.



< SERVICE BREAK DOWN >

apiVersion: v1: 
Specifies the API version for the Kubernetes Service.

kind: 
Service: Indicates that you are creating a Service resource in Kubernetes.

metadata:: 
This section contains metadata about the Service, such as its name.

name: my-app: 
Specifies the name of the Service, which is set to "my-app."

spec:: 
Defines the specifications for the Service.

selector:: 
This section defines a set of labels used to select the pods that the Service will route traffic to.

app: my-app: 
The selector specifies that the Service will route traffic to pods with the label "app: my-app," 
matching the labels of the pods created by the Deployment.

ports:: 
This section specifies the ports that the Service will listen on.

- protocol: TCP: Indicates that the Service is using the TCP protocol.

port: 80: 
Specifies the port on which the Service will listen. This is the port through which external 
clients can access the Service.

targetPort: 8080: 
Specifies the target port to which traffic will be routed within the pods. 
This matches the container port of the pods created by the Deployment. In this case, it routes 
traffic to port 8080 within the pods.


